{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muffafa/advent-of-haystack-2024-2025-solutions/blob/main/Solution_Santa_Haystack_self_reflecting_Gift_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7qE-VXQKnWW"
      },
      "source": [
        "# Advent of Haystack: Day 9\n",
        "In this challenge, you'll help Santa build a self-reflecting gift selection agent using Haystack and MongoDB Atlas! 🎅\n",
        "\n",
        "The agent will help optimize gift selections based on children's wishlists and budget constraints, using MongoDB Atlas vector search for semantic matching and implementing self-reflection to ensure the best possible gift combinations.\n",
        "\n",
        "**Components to use in this challenge:**\n",
        "- [`OpenAITextEmbedder`](https://docs.haystack.deepset.ai/docs/openaitextembedder) for  query embedding\n",
        "- [`MongoDBAtlasEmbeddingRetriever`](https://docs.haystack.deepset.ai/docs/) for finding relevant gifts\n",
        "- [`PromptBuilder`](https://docs.haystack.deepset.ai/docs/promptbuilder) for creating the prompt\n",
        "- [`OpenAIGenerator`](https://docs.haystack.deepset.ai/docs/openaigenerator) for  generating responses\n",
        "- Custom `GiftChecker` component for self-reflection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMTHZTGJKnWX",
        "outputId": "8d82e737-ec3f-4901-f087-d1e61181a3ea"
      },
      "source": [
        "# Install required packages\n",
        "!pip install haystack-ai mongodb-atlas-haystack tiktoken datasets colorama"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting haystack-ai\n",
            "  Downloading haystack_ai-2.8.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting mongodb-atlas-haystack\n",
            "  Downloading mongodb_atlas_haystack-1.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting haystack-experimental (from haystack-ai)\n",
            "  Downloading haystack_experimental-0.4.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (3.1.4)\n",
            "Collecting lazy-imports (from haystack-ai)\n",
            "  Downloading lazy_imports-0.3.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (10.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (1.26.4)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (1.57.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (2.2.2)\n",
            "Collecting posthog (from haystack-ai)\n",
            "  Downloading posthog-3.7.4-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (2.8.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0 in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (9.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (4.12.2)\n",
            "Collecting pymongo[srv] (from mongodb-atlas-haystack)\n",
            "  Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->haystack-ai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->haystack-ai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->haystack-ai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->haystack-ai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->haystack-ai) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->haystack-ai) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->haystack-ai) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->haystack-ai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->haystack-ai) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->haystack-ai) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->haystack-ai) (3.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->haystack-ai) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->haystack-ai) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->haystack-ai) (1.17.0)\n",
            "Collecting monotonic>=1.5 (from posthog->haystack-ai)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog->haystack-ai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "\u001b[33mWARNING: pymongo 4.10.1 does not provide the extra 'srv'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting dnspython<3.0.0,>=1.16.0 (from pymongo[srv]->mongodb-atlas-haystack)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->haystack-ai) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.1.0->haystack-ai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.1.0->haystack-ai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->haystack-ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->haystack-ai) (2.27.1)\n",
            "Downloading haystack_ai-2.8.0-py3-none-any.whl (391 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m391.4/391.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mongodb_atlas_haystack-1.0.0-py3-none-any.whl (14 kB)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading haystack_experimental-0.4.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.8/109.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lazy_imports-0.3.1-py3-none-any.whl (12 kB)\n",
            "Downloading posthog-3.7.4-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: monotonic, xxhash, lazy-imports, fsspec, dnspython, dill, colorama, backoff, tiktoken, pymongo, posthog, multiprocess, datasets, haystack-experimental, haystack-ai, mongodb-atlas-haystack\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 colorama-0.4.6 datasets-3.2.0 dill-0.3.8 dnspython-2.7.0 fsspec-2024.9.0 haystack-ai-2.8.0 haystack-experimental-0.4.0 lazy-imports-0.3.1 mongodb-atlas-haystack-1.0.0 monotonic-1.6 multiprocess-0.70.16 posthog-3.7.4 pymongo-4.10.1 tiktoken-0.8.0 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jsbb99NzKnWX"
      },
      "source": [
        "## Configure Environment\n",
        "\n",
        "- [OpenAI API Key](https://platform.openai.com/api-keys) if you'd like to use OpenAI embedding and text generation models\n",
        "- [MongoDB Atlas project](https://www.mongodb.com/docs/atlas/getting-started/) with an Atlas cluster (free tier works). [Detailed Tutorial](https://www.mongodb.com/docs/guides/atlas/cluster/#create-a-cluster)\n",
        "- Get your [connection string](https://www.mongodb.com/docs/atlas/tutorial/connect-to-your-cluster/#connect-to-your-atlas-cluster) and have `0.0.0.0/0` address in your network access list.\n",
        "- Connection string looks like this `mongodb+srv://<db_username>:<db_password>@<clustername>.xxxxx.mongodb.net/?retryWrites=true...`\n",
        "\n",
        "Set up your MongoDB Atlas and OpenAI credentials:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPQ6rWPWKnWX"
      },
      "source": [
        "import os\n",
        "import getpass\n",
        "import re\n",
        "\n",
        "conn_str = getpass.getpass(\"Enter your MongoDB connection string:\")\n",
        "conn_str = (re.sub(r'appName=[^\\s]*', 'appName=devrel.ai.haystack_partner', conn_str)\n",
        "            if 'appName=' in conn_str\n",
        "            else conn_str + ('&' if '?' in conn_str else '?') + 'appName=devrel.ai.haystack_partner')\n",
        "os.environ['MONGO_CONNECTION_STRING']=conn_str\n",
        "os.environ['OPENAI_API_KEY'] = getpass.getpass(\"Enter your OpenAI API Key:\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pioj7eg5KnWX"
      },
      "source": [
        "## Create Sample Gift Dataset\n",
        "\n",
        "Let's create a dataset of gifts with prices and categories:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpYX2h6wKnWX"
      },
      "source": [
        "dataset = {\n",
        "    \"train\": [\n",
        "        {\n",
        "            \"title\": \"LEGO Star Wars Set\",\n",
        "            \"price\": \"$49.99\",\n",
        "            \"description\": \"Build your own galaxy with this exciting LEGO Star Wars set\",\n",
        "            \"category\": \"Toys\",\n",
        "            \"age_range\": \"7-12\"\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Remote Control Car\",\n",
        "            \"price\": \"$29.99\",\n",
        "            \"description\": \"Fast and fun RC car with full directional control\",\n",
        "            \"category\": \"Toys\",\n",
        "            \"age_range\": \"6-10\"\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Art Set\",\n",
        "            \"price\": \"$24.99\",\n",
        "            \"description\": \"Complete art set with paints, brushes, and canvas\",\n",
        "            \"category\": \"Arts & Crafts\",\n",
        "            \"age_range\": \"5-15\"\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Science Kit\",\n",
        "            \"price\": \"$34.99\",\n",
        "            \"description\": \"Educational science experiments kit\",\n",
        "            \"category\": \"Educational\",\n",
        "            \"age_range\": \"8-14\"\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Dollhouse\",\n",
        "            \"price\": \"$89.99\",\n",
        "            \"description\": \"Beautiful wooden dollhouse with furniture\",\n",
        "            \"category\": \"Toys\",\n",
        "            \"age_range\": \"4-10\"\n",
        "        }\n",
        "    ]\n",
        "}"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OX6js4s4KnWX"
      },
      "source": [
        "## Initialize MongoDB Atlas\n",
        "\n",
        "First, we need to set up our MongoDB Atlas collection and create a vector search index. This step is crucial for enabling semantic search capabilities:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create collection gifts and add the vector index\n",
        "\n",
        "from pymongo import MongoClient\n",
        "from bson import json_util\n",
        "from pymongo.operations import SearchIndexModel\n",
        "import json\n",
        "import time\n",
        "\n",
        "client = MongoClient(os.environ['MONGO_CONNECTION_STRING'])\n",
        "db = client['santa_workshop']\n",
        "collection = db['gifts']\n",
        "\n",
        "db.create_collection(\"gifts\")\n",
        "\n",
        "\n",
        "## create index\n",
        "search_index_model = SearchIndexModel(\n",
        "  definition={\n",
        "    \"fields\": [\n",
        "      {\n",
        "        \"type\": \"vector\",\n",
        "        \"numDimensions\": 1536,\n",
        "        \"path\": \"embedding\",\n",
        "        \"similarity\": \"cosine\"\n",
        "      },\n",
        "    ]\n",
        "  },\n",
        "  name=\"vector_index\",\n",
        "  type=\"vectorSearch\",\n",
        ")\n",
        "result = collection.create_search_index(model=search_index_model)\n",
        "print(\"New search index named \" + result + \" is building.\")\n",
        "# Wait for initial sync to complete\n",
        "print(\"Polling to check if the index is ready. This may take up to a minute.\")\n",
        "predicate=None\n",
        "if predicate is None:\n",
        "  predicate = lambda index: index.get(\"queryable\") is True\n",
        "while True:\n",
        "  indices = list(collection.list_search_indexes(result))\n",
        "  if len(indices) and predicate(indices[0]):\n",
        "    break\n",
        "  time.sleep(5)\n",
        "print(result + \" is ready for querying.\")\n",
        "client.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpySpbqbLOKw",
        "outputId": "9d55bba8-434c-434b-e4fb-ca3de6e33651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New search index named vector_index is building.\n",
            "Polling to check if the index is ready. This may take up to a minute.\n",
            "vector_index is ready for querying.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Document Store and Index Documents\n",
        "\n",
        "Now let's set up the [MongoDBAtlasDocumentStore](https://docs.haystack.deepset.ai/docs/mongodbatlasdocumentstore) and index our gift data:"
      ],
      "metadata": {
        "id": "YQ4Kv8dpofGp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6bmEu1WKnWY",
        "outputId": "9465a8f8-d51e-4a54-ebf7-858fceaa4ade"
      },
      "source": [
        "from haystack import Pipeline, Document\n",
        "from haystack.document_stores.types import DuplicatePolicy\n",
        "from haystack.components.writers import DocumentWriter\n",
        "from haystack.components.embedders import OpenAIDocumentEmbedder\n",
        "from haystack_integrations.document_stores.mongodb_atlas import MongoDBAtlasDocumentStore\n",
        "from bson import json_util\n",
        "\n",
        "# Initialize document store\n",
        "document_store = MongoDBAtlasDocumentStore(\n",
        "    database_name=\"santa_workshop\",\n",
        "    collection_name=\"gifts\",\n",
        "    vector_search_index=\"vector_index\",\n",
        ")\n",
        "\n",
        "# Convert dataset to documents\n",
        "insert_data = []\n",
        "for gift in dataset['train']:\n",
        "    doc_gift = json_util.loads(json_util.dumps(gift))\n",
        "    haystack_doc = Document(content=doc_gift['title'], meta=doc_gift)\n",
        "    insert_data.append(haystack_doc)\n",
        "\n",
        "# Create indexing pipeline\n",
        "doc_writer = DocumentWriter(document_store=document_store, policy=DuplicatePolicy.SKIP)\n",
        "doc_embedder = OpenAIDocumentEmbedder(model=\"text-embedding-3-small\", meta_fields_to_embed=[\"description\"])\n",
        "\n",
        "indexing_pipe = Pipeline()\n",
        "indexing_pipe.add_component(instance=doc_embedder, name=\"doc_embedder\")\n",
        "indexing_pipe.add_component(instance=doc_writer, name=\"doc_writer\")\n",
        "indexing_pipe.connect(\"doc_embedder.documents\", \"doc_writer.documents\")\n",
        "\n",
        "# Index the documents\n",
        "indexing_pipe.run({\"doc_embedder\": {\"documents\": insert_data}})"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'doc_embedder': {'meta': {'model': 'text-embedding-3-small',\n",
              "   'usage': {'prompt_tokens': 54, 'total_tokens': 54}}},\n",
              " 'doc_writer': {'documents_written': 5}}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2yjTDncKnWY"
      },
      "source": [
        "## TODO: Create Self-Reflecting Gift Selection Pipeline\n",
        "\n",
        "Now comes the fun part! Create a pipeline that can:\n",
        "1. Take a gift request query\n",
        "2. Find relevant gifts using vector search\n",
        "3. Self-reflect on selections to optimize for budget and preferences\n",
        "\n",
        "**HINT:** Learn how to write your component in [Docs: Creating Custom Components](https://docs.haystack.deepset.ai/docs/custom-components)\n",
        "\n",
        "Here's the basic structure to get you started:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMbXMUKWKnWY",
        "outputId": "5f68914e-b0e8-4804-83f7-10645c5c865a"
      },
      "source": [
        "from haystack.components.generators import OpenAIGenerator\n",
        "from haystack.components.builders.prompt_builder import PromptBuilder\n",
        "from haystack_integrations.components.retrievers.mongodb_atlas import MongoDBAtlasEmbeddingRetriever\n",
        "from haystack.components.embedders import OpenAITextEmbedder\n",
        "from colorama import Fore\n",
        "from typing import List\n",
        "from haystack import component\n",
        "\n",
        "@component\n",
        "class GiftChecker:\n",
        "    @component.output_types(gifts_to_check=str, gifts=str)\n",
        "    def run(self, replies: List[str]):\n",
        "        if 'DONE' in replies[0]:\n",
        "            return {\"gifts\": replies[0].replace('DONE', '')}\n",
        "        else:\n",
        "            print(Fore.RED + \"Not optimized yet, could find better gift combinations\")\n",
        "            return {\"gifts_to_check\": replies[0]}\n",
        "\n",
        "# Create prompt template\n",
        "prompt_template = \"\"\"\n",
        "    You are Santa's gift selection assistant . Below you have a list of available gifts with their prices.\n",
        "    Based on the child's wishlist and budget, suggest appropriate gifts that maximize joy while staying within budget.\n",
        "\n",
        "    Available Gifts:\n",
        "    {% for doc in documents %}\n",
        "        Gift: {{ doc.content }}\n",
        "        Price: {{ doc.meta['price']}}\n",
        "        Age Range: {{ doc.meta['age_range']}}\n",
        "    {% endfor %}\n",
        "\n",
        "    Query: {{query}}\n",
        "    {% if gifts_to_check %}\n",
        "        Previous gift selection: {{gifts_to_check[0]}}\n",
        "        Can we optimize this selection for better value within budget?\n",
        "        If optimal, say 'DONE' and return the selection\n",
        "        If not, suggest a better combination\n",
        "    {% endif %}\n",
        "\n",
        "    Gift Selection:\n",
        "\"\"\"\n",
        "\n",
        "# Create the pipeline\n",
        "gift_pipeline = Pipeline(max_runs_per_component=5)\n",
        "gift_pipeline.add_component(\"text_embedder\", OpenAITextEmbedder(model=\"text-embedding-3-small\"))\n",
        "gift_pipeline.add_component(\n",
        "    instance=MongoDBAtlasEmbeddingRetriever(document_store=document_store, top_k=5),\n",
        "    name=\"retriever\"\n",
        ")\n",
        "gift_pipeline.add_component(instance=PromptBuilder(template=prompt_template), name=\"prompt_builder\")\n",
        "gift_pipeline.add_component(instance=GiftChecker(), name=\"checker\")\n",
        "gift_pipeline.add_component(instance=OpenAIGenerator(model=\"gpt-4\"), name=\"llm\")\n",
        "\n",
        "# Connect components\n",
        "gift_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
        "gift_pipeline.connect(\"retriever.documents\", \"prompt_builder.documents\")\n",
        "gift_pipeline.connect(\"checker.gifts_to_check\", \"prompt_builder.gifts_to_check\")\n",
        "gift_pipeline.connect(\"prompt_builder\", \"llm\")\n",
        "gift_pipeline.connect(\"llm\", \"checker\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<haystack.core.pipeline.pipeline.Pipeline object at 0x7d5853ba7160>\n",
              "🚅 Components\n",
              "  - text_embedder: OpenAITextEmbedder\n",
              "  - retriever: MongoDBAtlasEmbeddingRetriever\n",
              "  - prompt_builder: PromptBuilder\n",
              "  - checker: GiftChecker\n",
              "  - llm: OpenAIGenerator\n",
              "🛤️ Connections\n",
              "  - text_embedder.embedding -> retriever.query_embedding (List[float])\n",
              "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
              "  - prompt_builder.prompt -> llm.prompt (str)\n",
              "  - checker.gifts_to_check -> prompt_builder.gifts_to_check (str)\n",
              "  - llm.replies -> checker.replies (List[str])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Vmg-VghKnWY"
      },
      "source": [
        "## Test the Gift Selection Pipeline\n",
        "\n",
        "Let's test our pipeline with a sample query:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-qDYOeiKnWY",
        "outputId": "bcb2afe5-5e35-4882-f1dd-257bae9b7789"
      },
      "source": [
        "query = \"Find gifts for a 9-year-old who loves science and building things. Budget: $100\"\n",
        "\n",
        "result = gift_pipeline.run(\n",
        "    {\n",
        "        \"text_embedder\": {\"text\": query},\n",
        "        \"prompt_builder\": {\"query\": query}\n",
        "    }\n",
        ")\n",
        "\n",
        "print(Fore.GREEN + result[\"checker\"][\"gifts\"])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mNot optimized yet, could find better gift combinations\n",
            "\u001b[32mScience Kit, LEGO Star Wars Set\n",
            "    Total cost: $84.98\n",
            "    This selection is under budget and suits the child's interest in science and building things.\n",
            "    So, Santa says, \"\"!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
