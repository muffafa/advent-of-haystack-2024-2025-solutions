{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muffafa/advent-of-haystack-2024-2025-solutions/blob/main/Solution_Santa_Haystack_self_reflecting_Gift_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7qE-VXQKnWW"
      },
      "source": [
        "# Advent of Haystack: Day 9\n",
        "In this challenge, you'll help Santa build a self-reflecting gift selection agent using Haystack and MongoDB Atlas! ğŸ…\n",
        "\n",
        "The agent will help optimize gift selections based on children's wishlists and budget constraints, using MongoDB Atlas vector search for semantic matching and implementing self-reflection to ensure the best possible gift combinations.\n",
        "\n",
        "**Components to use in this challenge:**\n",
        "- [`OpenAITextEmbedder`](https://docs.haystack.deepset.ai/docs/openaitextembedder) for  query embedding\n",
        "- [`MongoDBAtlasEmbeddingRetriever`](https://docs.haystack.deepset.ai/docs/) for finding relevant gifts\n",
        "- [`PromptBuilder`](https://docs.haystack.deepset.ai/docs/promptbuilder) for creating the prompt\n",
        "- [`OpenAIGenerator`](https://docs.haystack.deepset.ai/docs/openaigenerator) for  generating responses\n",
        "- Custom `GiftChecker` component for self-reflection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMTHZTGJKnWX",
        "outputId": "8d82e737-ec3f-4901-f087-d1e61181a3ea"
      },
      "source": [
        "# Install required packages\n",
        "!pip install haystack-ai mongodb-atlas-haystack tiktoken datasets colorama"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting haystack-ai\n",
            "  Downloading haystack_ai-2.8.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting mongodb-atlas-haystack\n",
            "  Downloading mongodb_atlas_haystack-1.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting haystack-experimental (from haystack-ai)\n",
            "  Downloading haystack_experimental-0.4.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (3.1.4)\n",
            "Collecting lazy-imports (from haystack-ai)\n",
            "  Downloading lazy_imports-0.3.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (10.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (1.26.4)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (1.57.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (2.2.2)\n",
            "Collecting posthog (from haystack-ai)\n",
            "  Downloading posthog-3.7.4-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (2.8.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0 in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (9.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (4.12.2)\n",
            "Collecting pymongo[srv] (from mongodb-atlas-haystack)\n",
            "  Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->haystack-ai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->haystack-ai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->haystack-ai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->haystack-ai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->haystack-ai) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->haystack-ai) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->haystack-ai) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->haystack-ai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->haystack-ai) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->haystack-ai) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->haystack-ai) (3.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->haystack-ai) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->haystack-ai) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->haystack-ai) (1.17.0)\n",
            "Collecting monotonic>=1.5 (from posthog->haystack-ai)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog->haystack-ai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "\u001b[33mWARNING: pymongo 4.10.1 does not provide the extra 'srv'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting dnspython<3.0.0,>=1.16.0 (from pymongo[srv]->mongodb-atlas-haystack)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->haystack-ai) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.1.0->haystack-ai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.1.0->haystack-ai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->haystack-ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->haystack-ai) (2.27.1)\n",
            "Downloading haystack_ai-2.8.0-py3-none-any.whl (391 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m391.4/391.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mongodb_atlas_haystack-1.0.0-py3-none-any.whl (14 kB)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading haystack_experimental-0.4.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m109.8/109.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lazy_imports-0.3.1-py3-none-any.whl (12 kB)\n",
            "Downloading posthog-3.7.4-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: monotonic, xxhash, lazy-imports, fsspec, dnspython, dill, colorama, backoff, tiktoken, pymongo, posthog, multiprocess, datasets, haystack-experimental, haystack-ai, mongodb-atlas-haystack\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 colorama-0.4.6 datasets-3.2.0 dill-0.3.8 dnspython-2.7.0 fsspec-2024.9.0 haystack-ai-2.8.0 haystack-experimental-0.4.0 lazy-imports-0.3.1 mongodb-atlas-haystack-1.0.0 monotonic-1.6 multiprocess-0.70.16 posthog-3.7.4 pymongo-4.10.1 tiktoken-0.8.0 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jsbb99NzKnWX"
      },
      "source": [
        "## Configure Environment\n",
        "\n",
        "- [OpenAI API Key](https://platform.openai.com/api-keys) if you'd like to use OpenAI embedding and text generation models\n",
        "- [MongoDB Atlas project](https://www.mongodb.com/docs/atlas/getting-started/) with an Atlas cluster (free tier works). [Detailed Tutorial](https://www.mongodb.com/docs/guides/atlas/cluster/#create-a-cluster)\n",
        "- Get your [connection string](https://www.mongodb.com/docs/atlas/tutorial/connect-to-your-cluster/#connect-to-your-atlas-cluster) and have `0.0.0.0/0` address in your network access list.\n",
        "- Connection string looks like this `mongodb+srv://<db_username>:<db_password>@<clustername>.xxxxx.mongodb.net/?retryWrites=true...`\n",
        "\n",
        "Set up your MongoDB Atlas and OpenAI credentials:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPQ6rWPWKnWX"
      },
      "source": [
        "import os\n",
        "import getpass\n",
        "import re\n",
        "\n",
        "conn_str = getpass.getpass(\"Enter your MongoDB connection string:\")\n",
        "conn_str = (re.sub(r'appName=[^\\s]*', 'appName=devrel.ai.haystack_partner', conn_str)\n",
        "            if 'appName=' in conn_str\n",
        "            else conn_str + ('&' if '?' in conn_str else '?') + 'appName=devrel.ai.haystack_partner')\n",
        "os.environ['MONGO_CONNECTION_STRING']=conn_str\n",
        "os.environ['OPENAI_API_KEY'] = getpass.getpass(\"Enter your OpenAI API Key:\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pioj7eg5KnWX"
      },
      "source": [
        "## Create Sample Gift Dataset\n",
        "\n",
        "Let's create a dataset of gifts with prices and categories:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpYX2h6wKnWX"
      },
      "source": [
        "dataset = {\n",
        "    \"train\": [\n",
        "        {\n",
        "            \"title\": \"LEGO Star Wars Set\",\n",
        "            \"price\": \"$49.99\",\n",
        "            \"description\": \"Build your own galaxy with this exciting LEGO Star Wars set\",\n",
        "            \"category\": \"Toys\",\n",
        "            \"age_range\": \"7-12\"\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Remote Control Car\",\n",
        "            \"price\": \"$29.99\",\n",
        "            \"description\": \"Fast and fun RC car with full directional control\",\n",
        "            \"category\": \"Toys\",\n",
        "            \"age_range\": \"6-10\"\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Art Set\",\n",
        "            \"price\": \"$24.99\",\n",
        "            \"description\": \"Complete art set with paints, brushes, and canvas\",\n",
        "            \"category\": \"Arts & Crafts\",\n",
        "            \"age_range\": \"5-15\"\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Science Kit\",\n",
        "            \"price\": \"$34.99\",\n",
        "            \"description\": \"Educational science experiments kit\",\n",
        "            \"category\": \"Educational\",\n",
        "            \"age_range\": \"8-14\"\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Dollhouse\",\n",
        "            \"price\": \"$89.99\",\n",
        "            \"description\": \"Beautiful wooden dollhouse with furniture\",\n",
        "            \"category\": \"Toys\",\n",
        "            \"age_range\": \"4-10\"\n",
        "        }\n",
        "    ]\n",
        "}"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OX6js4s4KnWX"
      },
      "source": [
        "## Initialize MongoDB Atlas\n",
        "\n",
        "First, we need to set up our MongoDB Atlas collection and create a vector search index. This step is crucial for enabling semantic search capabilities:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create collection gifts and add the vector index\n",
        "\n",
        "from pymongo import MongoClient\n",
        "from bson import json_util\n",
        "from pymongo.operations import SearchIndexModel\n",
        "import json\n",
        "import time\n",
        "\n",
        "client = MongoClient(os.environ['MONGO_CONNECTION_STRING'])\n",
        "db = client['santa_workshop']\n",
        "collection = db['gifts']\n",
        "\n",
        "db.create_collection(\"gifts\")\n",
        "\n",
        "\n",
        "## create index\n",
        "search_index_model = SearchIndexModel(\n",
        "  definition={\n",
        "    \"fields\": [\n",
        "      {\n",
        "        \"type\": \"vector\",\n",
        "        \"numDimensions\": 1536,\n",
        "        \"path\": \"embedding\",\n",
        "        \"similarity\": \"cosine\"\n",
        "      },\n",
        "    ]\n",
        "  },\n",
        "  name=\"vector_index\",\n",
        "  type=\"vectorSearch\",\n",
        ")\n",
        "result = collection.create_search_index(model=search_index_model)\n",
        "print(\"New search index named \" + result + \" is building.\")\n",
        "# Wait for initial sync to complete\n",
        "print(\"Polling to check if the index is ready. This may take up to a minute.\")\n",
        "predicate=None\n",
        "if predicate is None:\n",
        "  predicate = lambda index: index.get(\"queryable\") is True\n",
        "while True:\n",
        "  indices = list(collection.list_search_indexes(result))\n",
        "  if len(indices) and predicate(indices[0]):\n",
        "    break\n",
        "  time.sleep(5)\n",
        "print(result + \" is ready for querying.\")\n",
        "client.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpySpbqbLOKw",
        "outputId": "9d55bba8-434c-434b-e4fb-ca3de6e33651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New search index named vector_index is building.\n",
            "Polling to check if the index is ready. This may take up to a minute.\n",
            "vector_index is ready for querying.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Document Store and Index Documents\n",
        "\n",
        "Now let's set up the [MongoDBAtlasDocumentStore](https://docs.haystack.deepset.ai/docs/mongodbatlasdocumentstore) and index our gift data:"
      ],
      "metadata": {
        "id": "YQ4Kv8dpofGp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6bmEu1WKnWY",
        "outputId": "9465a8f8-d51e-4a54-ebf7-858fceaa4ade"
      },
      "source": [
        "from haystack import Pipeline, Document\n",
        "from haystack.document_stores.types import DuplicatePolicy\n",
        "from haystack.components.writers import DocumentWriter\n",
        "from haystack.components.embedders import OpenAIDocumentEmbedder\n",
        "from haystack_integrations.document_stores.mongodb_atlas import MongoDBAtlasDocumentStore\n",
        "from bson import json_util\n",
        "\n",
        "# Initialize document store\n",
        "document_store = MongoDBAtlasDocumentStore(\n",
        "    database_name=\"santa_workshop\",\n",
        "    collection_name=\"gifts\",\n",
        "    vector_search_index=\"vector_index\",\n",
        ")\n",
        "\n",
        "# Convert dataset to documents\n",
        "insert_data = []\n",
        "for gift in dataset['train']:\n",
        "    doc_gift = json_util.loads(json_util.dumps(gift))\n",
        "    haystack_doc = Document(content=doc_gift['title'], meta=doc_gift)\n",
        "    insert_data.append(haystack_doc)\n",
        "\n",
        "# Create indexing pipeline\n",
        "doc_writer = DocumentWriter(document_store=document_store, policy=DuplicatePolicy.SKIP)\n",
        "doc_embedder = OpenAIDocumentEmbedder(model=\"text-embedding-3-small\", meta_fields_to_embed=[\"description\"])\n",
        "\n",
        "indexing_pipe = Pipeline()\n",
        "indexing_pipe.add_component(instance=doc_embedder, name=\"doc_embedder\")\n",
        "indexing_pipe.add_component(instance=doc_writer, name=\"doc_writer\")\n",
        "indexing_pipe.connect(\"doc_embedder.documents\", \"doc_writer.documents\")\n",
        "\n",
        "# Index the documents\n",
        "indexing_pipe.run({\"doc_embedder\": {\"documents\": insert_data}})"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.25it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'doc_embedder': {'meta': {'model': 'text-embedding-3-small',\n",
              "   'usage': {'prompt_tokens': 54, 'total_tokens': 54}}},\n",
              " 'doc_writer': {'documents_written': 5}}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2yjTDncKnWY"
      },
      "source": [
        "## TODO: Create Self-Reflecting Gift Selection Pipeline\n",
        "\n",
        "Now comes the fun part! Create a pipeline that can:\n",
        "1. Take a gift request query\n",
        "2. Find relevant gifts using vector search\n",
        "3. Self-reflect on selections to optimize for budget and preferences\n",
        "\n",
        "**HINT:** Learn how to write your component in [Docs: Creating Custom Components](https://docs.haystack.deepset.ai/docs/custom-components)\n",
        "\n",
        "Here's the basic structure to get you started:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMbXMUKWKnWY",
        "outputId": "5f68914e-b0e8-4804-83f7-10645c5c865a"
      },
      "source": [
        "from haystack.components.generators import OpenAIGenerator\n",
        "from haystack.components.builders.prompt_builder import PromptBuilder\n",
        "from haystack_integrations.components.retrievers.mongodb_atlas import MongoDBAtlasEmbeddingRetriever\n",
        "from haystack.components.embedders import OpenAITextEmbedder\n",
        "from colorama import Fore\n",
        "from typing import List\n",
        "from haystack import component\n",
        "\n",
        "@component\n",
        "class GiftChecker:\n",
        "    @component.output_types(gifts_to_check=str, gifts=str)\n",
        "    def run(self, replies: List[str]):\n",
        "        if 'DONE' in replies[0]:\n",
        "            return {\"gifts\": replies[0].replace('DONE', '')}\n",
        "        else:\n",
        "            print(Fore.RED + \"Not optimized yet, could find better gift combinations\")\n",
        "            return {\"gifts_to_check\": replies[0]}\n",
        "\n",
        "# Create prompt template\n",
        "prompt_template = \"\"\"\n",
        "    You are Santa's gift selection assistant . Below you have a list of available gifts with their prices.\n",
        "    Based on the child's wishlist and budget, suggest appropriate gifts that maximize joy while staying within budget.\n",
        "\n",
        "    Available Gifts:\n",
        "    {% for doc in documents %}\n",
        "        Gift: {{ doc.content }}\n",
        "        Price: {{ doc.meta['price']}}\n",
        "        Age Range: {{ doc.meta['age_range']}}\n",
        "    {% endfor %}\n",
        "\n",
        "    Query: {{query}}\n",
        "    {% if gifts_to_check %}\n",
        "        Previous gift selection: {{gifts_to_check[0]}}\n",
        "        Can we optimize this selection for better value within budget?\n",
        "        If optimal, say 'DONE' and return the selection\n",
        "        If not, suggest a better combination\n",
        "    {% endif %}\n",
        "\n",
        "    Gift Selection:\n",
        "\"\"\"\n",
        "\n",
        "# Create the pipeline\n",
        "gift_pipeline = Pipeline(max_runs_per_component=5)\n",
        "gift_pipeline.add_component(\"text_embedder\", OpenAITextEmbedder(model=\"text-embedding-3-small\"))\n",
        "gift_pipeline.add_component(\n",
        "    instance=MongoDBAtlasEmbeddingRetriever(document_store=document_store, top_k=5),\n",
        "    name=\"retriever\"\n",
        ")\n",
        "gift_pipeline.add_component(instance=PromptBuilder(template=prompt_template), name=\"prompt_builder\")\n",
        "gift_pipeline.add_component(instance=GiftChecker(), name=\"checker\")\n",
        "gift_pipeline.add_component(instance=OpenAIGenerator(model=\"gpt-4\"), name=\"llm\")\n",
        "\n",
        "# Connect components\n",
        "gift_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
        "gift_pipeline.connect(\"retriever.documents\", \"prompt_builder.documents\")\n",
        "gift_pipeline.connect(\"checker.gifts_to_check\", \"prompt_builder.gifts_to_check\")\n",
        "gift_pipeline.connect(\"prompt_builder\", \"llm\")\n",
        "gift_pipeline.connect(\"llm\", \"checker\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<haystack.core.pipeline.pipeline.Pipeline object at 0x7d5853ba7160>\n",
              "ğŸš… Components\n",
              "  - text_embedder: OpenAITextEmbedder\n",
              "  - retriever: MongoDBAtlasEmbeddingRetriever\n",
              "  - prompt_builder: PromptBuilder\n",
              "  - checker: GiftChecker\n",
              "  - llm: OpenAIGenerator\n",
              "ğŸ›¤ï¸ Connections\n",
              "  - text_embedder.embedding -> retriever.query_embedding (List[float])\n",
              "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
              "  - prompt_builder.prompt -> llm.prompt (str)\n",
              "  - checker.gifts_to_check -> prompt_builder.gifts_to_check (str)\n",
              "  - llm.replies -> checker.replies (List[str])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Vmg-VghKnWY"
      },
      "source": [
        "## Test the Gift Selection Pipeline\n",
        "\n",
        "Let's test our pipeline with a sample query:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-qDYOeiKnWY",
        "outputId": "bcb2afe5-5e35-4882-f1dd-257bae9b7789"
      },
      "source": [
        "query = \"Find gifts for a 9-year-old who loves science and building things. Budget: $100\"\n",
        "\n",
        "result = gift_pipeline.run(\n",
        "    {\n",
        "        \"text_embedder\": {\"text\": query},\n",
        "        \"prompt_builder\": {\"query\": query}\n",
        "    }\n",
        ")\n",
        "\n",
        "print(Fore.GREEN + result[\"checker\"][\"gifts\"])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mNot optimized yet, could find better gift combinations\n",
            "\u001b[32mScience Kit, LEGO Star Wars Set\n",
            "    Total cost: $84.98\n",
            "    This selection is under budget and suits the child's interest in science and building things.\n",
            "    So, Santa says, \"\"!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
