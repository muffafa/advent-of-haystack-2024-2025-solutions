{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5q2FHwPY-wqJ"
      },
      "source": [
        "# Advent of Haystack: Day 1\n",
        "_Make a copy of this Colab to start!_\n",
        "\n",
        "In this first challenge, we are going to build a pipeline that answers questions based on the contents of a URL. The given pipeline works as it, but your task is to complete the connnections and add the **other required two components**👇\n",
        "\n",
        "**You should complete the missing sections in step 3, 4 and 5**\n",
        "\n",
        "### Initial Components to use:\n",
        "- [`LinkContentFetcher`](https://docs.haystack.deepset.ai/docs/linkcontentfetcher) for using the contents of several URLs in your pipeline\n",
        "- [`HTMLToDocument`](https://docs.haystack.deepset.ai/docs/htmltodocument) for converting the HTML files into documents.\n",
        "- [`PromptBuilder`](https://docs.haystack.deepset.ai/docs/promptbuilder) for creating the prompt\n",
        "- [`OpenAIGenerator`](https://docs.haystack.deepset.ai/docs/openaigenerator) for generating responses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZALZDx-LFebK"
      },
      "source": [
        "### 1) Installation\n",
        "\n",
        "Install `haystack-ai`, `trafilatura` and `sentence-transformers` packages with `pip`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QJJ5AT3Z79e3"
      },
      "outputs": [],
      "source": [
        "!pip install haystack-ai trafilatura \"sentence-transformers>=3.0.0\"\n",
        "!pip install -q --upgrade openai # not to get the OpenAI proxies error: https://community.openai.com/t/error-with-openai-1-56-0-client-init-got-an-unexpected-keyword-argument-proxies/1040332/2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSgeNUYxXLyI"
      },
      "source": [
        "### (Optional) Change the Logging Level\n",
        "\n",
        "This way, not only warnings but also information messages are displayed in the console output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0k3LE27XKf0"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
        "logging.getLogger(\"haystack\").setLevel(logging.DEBUG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3jwS4A_FmEV"
      },
      "source": [
        "### 2) Enter API key for OpenAI\n",
        "If you will use OpenAI models, save your API key as `OPENAI_API_KEY` environment variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy4xBS6v8n1s",
        "outputId": "a16f94b9-01dd-4b47-a356-c9a6447ef474"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter OpenAI API key:··········\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85pAAbaPFtZc"
      },
      "source": [
        "### 3) Create components\n",
        "\n",
        "Initialize two components to complete the pipeline.\n",
        "\n",
        "**Hints**:\n",
        "* One component is to split the documents into smaller chunks of 10 sentences each.\n",
        "* As the other component, consider methods or components you can use to filter out irrelevant chunks by ranking before injecting the context into the prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qI4OaTHBa-vt"
      },
      "outputs": [],
      "source": [
        "from haystack.components.fetchers import LinkContentFetcher\n",
        "from haystack.components.converters import HTMLToDocument\n",
        "from haystack.components.builders import PromptBuilder\n",
        "from haystack.components.generators import OpenAIGenerator\n",
        "\n",
        "fetcher = LinkContentFetcher()\n",
        "converter = HTMLToDocument()\n",
        "#### INITIALIZE THE MISSING COMPONENTS HERE ####\n",
        "# comp_one = ...\n",
        "# comp_two = ...\n",
        "################################################\n",
        "template = \"\"\"Given the information below, answer the query. Only use the provided context to generate the answer and output the used document links\n",
        "            Context:\n",
        "            {% for document in documents %}\n",
        "                {{ document.content }}\n",
        "                URL: {{ document.meta.url }}\n",
        "            {% endfor %}\n",
        "\n",
        "            Question: {{ query }}\n",
        "            Answer:\"\"\"\n",
        "\n",
        "prompt_builder = PromptBuilder(template = template)\n",
        "generator = OpenAIGenerator(model=\"gpt-4o-mini\") # Feel free to try different models or different providers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnDhrfD5AayG"
      },
      "source": [
        "### 4) Add them to a Haystack Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIXUQWG5AYg6"
      },
      "outputs": [],
      "source": [
        "from haystack import Pipeline\n",
        "\n",
        "pipeline = Pipeline()\n",
        "pipeline.add_component(name=\"fetcher\", instance=fetcher)\n",
        "pipeline.add_component(name=\"converter\", instance=converter)\n",
        "#### ADD MISSING COMPONENTS HERE ####\n",
        "pipeline.add_component(.....)\n",
        "pipeline.add_component(....)\n",
        "#####################################\n",
        "pipeline.add_component(name=\"prompt_builder\", instance=prompt_builder)\n",
        "pipeline.add_component(name=\"generator\", instance=generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFQOOQkaAeRr"
      },
      "source": [
        "###5) Connect the components\n",
        "\n",
        "Complete the pipeline connections to achieve a working pipeline that can be run.\n",
        "\n",
        "**Note:** Everytime you want to run cell 4 and cell 5, you need to run cell 3 and reinitialize all components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpDVUIhlAi0l"
      },
      "outputs": [],
      "source": [
        "#### CONNECT ALL COMPONENTS HERE ####\n",
        "\n",
        "#####################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0eEFSDYAjOU"
      },
      "source": [
        "###6) Visualize the Pipeline 🎨\n",
        "\n",
        "Display the pipeline image with [`show()`](https://docs.haystack.deepset.ai/docs/visualizing-pipelines) method to understand the connections between components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctE6bDESAqv8"
      },
      "outputs": [],
      "source": [
        "pipeline.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2v6GZs6Am5O"
      },
      "source": [
        "###7) Run the Pipeline\n",
        "\n",
        "Use the URLs below and try the example queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gbo1QwM9Ambj"
      },
      "outputs": [],
      "source": [
        "urls = [\"https://haystack.deepset.ai/blog/extracting-metadata-filter\",\n",
        "        \"https://haystack.deepset.ai/blog/query-expansion\",\n",
        "        \"https://haystack.deepset.ai/blog/query-decomposition\",\n",
        "        \"https://haystack.deepset.ai/cookbook/metadata_enrichment\"]\n",
        "\n",
        "## Example queries you can try\n",
        "query = \"What is the difference between metadata filtering and metadata enrichment?\"\n",
        "# query = \"Which methods can I use to transform query for better retrieval?\"\n",
        "# query = \"How can I use metadata to improve retrieval?\"\n",
        "# query = \"What's preprocessing?\" # Should return no answer\n",
        "\n",
        "## Add parameters\n",
        "result = pipeline.run(data={\"fetcher\": {\"urls\": urls}, \"prompt_builder\": {\"query\": query}})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwTvayX3nbAj"
      },
      "source": [
        "Print the LLM response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLdqes3NaV4S"
      },
      "outputs": [],
      "source": [
        "print(result['generator']['replies'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5QCnpvJuPX6"
      },
      "source": [
        "### (Optional) Bonus Task\n",
        "\n",
        "Try to recreate the same pipeline but this time, use [OpenAIChatGenerator](https://docs.haystack.deepset.ai/docs/openaichatgenerator) and [ChatPromptBuilder](https://docs.haystack.deepset.ai/docs/chatpromptbuilder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhN3Lv1tvKdt"
      },
      "outputs": [],
      "source": [
        "from haystack.components.generators.chat import OpenAIChatGenerator\n",
        "from haystack.components.builders import ChatPromptBuilder\n",
        "from haystack.dataclasses import ChatMessage\n",
        "\n",
        "...."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}